{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install prince"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nMibQ0rVofB",
        "outputId": "8c69267c-e87f-4b4e-c259-963aecfec938"
      },
      "id": "5nMibQ0rVofB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting prince\n",
            "  Downloading prince-0.13.1-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: altair<6.0.0,>=4.2.2 in /usr/local/lib/python3.10/dist-packages (from prince) (4.2.2)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from prince) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from prince) (1.5.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (1.26.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (0.12.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (3.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (0.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.4.1->prince) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6.0.0,>=4.2.2->prince) (3.0.2)\n",
            "Downloading prince-0.13.1-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.8/415.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: prince\n",
            "Successfully installed prince-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Impute numerical columns with the mean\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
        "\n",
        "# Impute categorical columns with the most frequent value\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
        "\n",
        "# Replace `prince.FAMD` with column transformer for numerical/categorical handling\n",
        "# Assuming a custom FAMD implementation or equivalent transformation\n",
        "X_num = df[num_cols].drop(columns=['SalePrice'])\n",
        "X_cat = pd.get_dummies(df[cat_cols], drop_first=True)  # One-hot encode categorical features\n",
        "X = pd.concat([X_num, X_cat], axis=1)\n",
        "\n",
        "# Define the target variable\n",
        "y = df['SalePrice']\n",
        "\n",
        "# Define PCA toggle in pipeline\n",
        "def create_pipeline(model, use_pca=False):\n",
        "    steps = [\n",
        "        ('preprocessor', ColumnTransformer(\n",
        "            transformers=[('scaler', StandardScaler(), X_num.columns)],\n",
        "            remainder='passthrough'  # Pass categorical columns through\n",
        "        ))\n",
        "    ]\n",
        "    if use_pca:\n",
        "        steps.append(('pca', PCA(n_components=0.95)))\n",
        "    steps.append(('model', model))\n",
        "    return Pipeline(steps)\n",
        "\n",
        "# Define scorer (using RMSE for calculation, NRMSE for reporting)\n",
        "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
        "\n",
        "# Define models and hyperparameters\n",
        "alphas = [0.01, 0.1, 1, 10, 100]\n",
        "models = [\n",
        "    ('LinearRegression', LinearRegression(), None),\n",
        "    ('Ridge', Ridge(), {'model__alpha': alphas}),\n",
        "    ('Lasso', Lasso(max_iter=10000), {'model__alpha': alphas}),\n",
        "]\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# Train models on datasets with/without PCA\n",
        "for use_pca in [False, True]:\n",
        "    for model_name, model, param_grid in models:\n",
        "        pipeline = create_pipeline(model, use_pca)\n",
        "\n",
        "        if param_grid:\n",
        "            grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring=rmse_scorer, n_jobs=-1)\n",
        "            grid_search.fit(X, y)\n",
        "            best_model = grid_search.best_estimator_\n",
        "            rmse = -grid_search.best_score_\n",
        "            best_params = grid_search.best_params_\n",
        "        else:\n",
        "            scores = cross_val_score(pipeline, X, y, cv=10, scoring=rmse_scorer, n_jobs=-1)\n",
        "            rmse = -scores.mean()\n",
        "            best_params = None\n",
        "\n",
        "        nrmse = rmse / y.mean()\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            'Dataset': 'Complete',  # Adjust if multiple datasets are tested\n",
        "            'PCA': use_pca,\n",
        "            'Model': model_name,\n",
        "            'Best Params': best_params,\n",
        "            'RMSE': rmse,\n",
        "            'NRMSE': nrmse\n",
        "        })\n",
        "\n",
        "# Convert results to DataFrame for analysis\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Sort results by NRMSE for better interpretation\n",
        "results_df = results_df.sort_values(by='NRMSE').reset_index(drop=True)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP7orxHIOYAm",
        "outputId": "37d70f37-3827-4c7a-aa0a-1355182e6cbc"
      },
      "id": "yP7orxHIOYAm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Dataset    PCA             Model             Best Params          RMSE  \\\n",
            "0  Complete  False  LinearRegression                    None -7.653694e+14   \n",
            "1  Complete  False             Lasso  {'model__alpha': 0.01} -4.096312e+04   \n",
            "2  Complete  False             Ridge  {'model__alpha': 0.01} -3.934767e+04   \n",
            "3  Complete   True  LinearRegression                    None -3.328655e+04   \n",
            "4  Complete   True             Lasso  {'model__alpha': 0.01} -3.328652e+04   \n",
            "5  Complete   True             Ridge  {'model__alpha': 0.01} -3.328642e+04   \n",
            "\n",
            "          NRMSE  \n",
            "0 -4.230402e+09  \n",
            "1 -2.264142e-01  \n",
            "2 -2.174851e-01  \n",
            "3 -1.839837e-01  \n",
            "4 -1.839836e-01  \n",
            "5 -1.839830e-01  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Impute missing values\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
        "\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
        "\n",
        "# Define the target variable\n",
        "y = df['SalePrice']\n",
        "\n",
        "# Dataset preprocessing\n",
        "def preprocess_dataset(df, apply_pca=False):\n",
        "    \"\"\"Preprocess dataset with optional PCA.\"\"\"\n",
        "    # Separate numerical and categorical features\n",
        "    X_num = df[num_cols].drop(columns=['SalePrice'], errors='ignore')\n",
        "    X_cat = pd.get_dummies(df[cat_cols], drop_first=True)\n",
        "    X = pd.concat([X_num, X_cat], axis=1)\n",
        "\n",
        "    if apply_pca:\n",
        "        pca = PCA(n_components=0.95)  # Retain 95% variance\n",
        "        X = pca.fit_transform(X)\n",
        "        X = pd.DataFrame(X)  # Wrap PCA-transformed array as DataFrame\n",
        "    return X\n",
        "\n",
        "# Define NRMSE scorer\n",
        "def normalized_rmse(y_true, y_pred):\n",
        "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return rmse / y_true.mean()\n",
        "\n",
        "nrmse_scorer = make_scorer(normalized_rmse, greater_is_better=False)\n",
        "\n",
        "# Hyperparameters\n",
        "alphas = [0.01, 0.1, 1, 10, 100]\n",
        "polynomial_degree = 2  # Degree of polynomial features\n",
        "\n",
        "# Models and pipelines\n",
        "def build_pipeline(model, degree, apply_pca=False):\n",
        "    \"\"\"Build a pipeline with scaling, polynomial features, and an optional PCA step.\"\"\"\n",
        "    steps = [\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('poly', PolynomialFeatures(degree=degree))\n",
        "    ]\n",
        "    if apply_pca:\n",
        "        steps.append(('pca', PCA(n_components=0.95)))\n",
        "    steps.append(('model', model))\n",
        "    return Pipeline(steps)\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# Evaluate models across datasets and settings\n",
        "for apply_pca in [False, True]:\n",
        "    X = preprocess_dataset(df, apply_pca=apply_pca)\n",
        "\n",
        "    # --- Polynomial Regression ---\n",
        "    poly_pipeline = build_pipeline(LinearRegression(), polynomial_degree, apply_pca)\n",
        "    poly_rmse_scores = -cross_val_score(poly_pipeline, X, y, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "    results.append({\n",
        "        'Dataset': 'Complete',\n",
        "        'PCA': apply_pca,\n",
        "        'Model': 'PolynomialRegression',\n",
        "        'Best Alpha': None,\n",
        "        'NRMSE': poly_rmse_scores.mean()\n",
        "    })\n",
        "\n",
        "    # --- Ridge Regression ---\n",
        "    ridge_pipeline = build_pipeline(Ridge(), polynomial_degree, apply_pca)\n",
        "    ridge_param_grid = {'model__alpha': alphas}\n",
        "    ridge_grid = GridSearchCV(ridge_pipeline, ridge_param_grid, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "    ridge_grid.fit(X, y)\n",
        "    results.append({\n",
        "        'Dataset': 'Complete',\n",
        "        'PCA': apply_pca,\n",
        "        'Model': 'RidgePoly',\n",
        "        'Best Alpha': ridge_grid.best_params_['model__alpha'],\n",
        "        'NRMSE': -ridge_grid.best_score_\n",
        "    })\n",
        "\n",
        "    # --- Lasso Regression ---\n",
        "    lasso_pipeline = build_pipeline(Lasso(max_iter=10000), polynomial_degree, apply_pca)\n",
        "    lasso_param_grid = {'model__alpha': alphas}\n",
        "    lasso_grid = GridSearchCV(lasso_pipeline, lasso_param_grid, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "    lasso_grid.fit(X, y)\n",
        "    results.append({\n",
        "        'Dataset': 'Complete',\n",
        "        'PCA': apply_pca,\n",
        "        'Model': 'LassoPoly',\n",
        "        'Best Alpha': lasso_grid.best_params_['model__alpha'],\n",
        "        'NRMSE': -lasso_grid.best_score_\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame and sort\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='NRMSE').reset_index(drop=True)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "4W2Kk1anPcuV"
      },
      "id": "4W2Kk1anPcuV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}