{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install prince"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nMibQ0rVofB",
        "outputId": "8c69267c-e87f-4b4e-c259-963aecfec938"
      },
      "id": "5nMibQ0rVofB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting prince\n",
            "  Downloading prince-0.13.1-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: altair<6.0.0,>=4.2.2 in /usr/local/lib/python3.10/dist-packages (from prince) (4.2.2)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from prince) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from prince) (1.5.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (1.26.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (0.12.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (3.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (0.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.4.1->prince) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6.0.0,>=4.2.2->prince) (3.0.2)\n",
            "Downloading prince-0.13.1-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.8/415.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: prince\n",
            "Successfully installed prince-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "import prince\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load the dataset (assuming the original dataset is loaded into df)\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Impute numerical columns with the mean\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
        "\n",
        "# Impute categorical columns with the most frequent value\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
        "\n",
        "# Apply FAMD after imputation\n",
        "famd = prince.FAMD(n_components=10, random_state=42)\n",
        "famd_df = famd.fit_transform(df.drop(columns=['SalePrice']))\n",
        "\n",
        "# Define the target variable\n",
        "y = df['SalePrice']\n",
        "\n",
        "# Define datasets based on available features (replace these with your own data preprocessing as needed)\n",
        "datasets = {\n",
        "    \"numerical\": df[['GrLivArea', 'TotalBsmtSF', 'YearBuilt', 'LotArea']],\n",
        "    \"complete\": df.drop(columns=['SalePrice']),  # Assuming all features except target\n",
        "    \"famd\": famd_df  # Replace `famd_df` with your actual famd dataset if preprocessed separately\n",
        "}\n",
        "\n",
        "# Define NRMSE scorer\n",
        "def normalized_rmse(y_true, y_pred):\n",
        "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return rmse / y_true.mean()\n",
        "\n",
        "nrmse_scorer = make_scorer(normalized_rmse, greater_is_better=False)\n",
        "\n",
        "# Define Ridge and Lasso hyperparameters\n",
        "alphas = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through datasets\n",
        "for dataset_name, X in datasets.items():\n",
        "    # Loop through PCA options (with and without)\n",
        "    for apply_pca in [False, True]:\n",
        "        # Apply PCA if selected\n",
        "        if apply_pca:\n",
        "            # One-hot encode categorical columns before applying PCA\n",
        "            X_transformed = pd.get_dummies(X, drop_first=True)\n",
        "            pca = PCA(n_components=0.95)  # Adjusted to retain 95% of variance\n",
        "            X_transformed = pca.fit_transform(X_transformed)\n",
        "            # Wrap the PCA-transformed data in a DataFrame\n",
        "            X_transformed = pd.DataFrame(X_transformed)\n",
        "        else:\n",
        "            # If no PCA, one-hot encode categorical columns\n",
        "            X_transformed = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "        # Standard scaler to ensure features are on the same scale\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # --- Regular Linear Regression ---\n",
        "        linear_pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('linear', LinearRegression())\n",
        "        ])\n",
        "\n",
        "        # Evaluate Linear Regression with cross-validation\n",
        "        linear_rmse_scores = -cross_val_score(linear_pipeline, X_transformed, y, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "        linear_rmse = linear_rmse_scores.mean()\n",
        "\n",
        "        # Store Linear Regression results\n",
        "        results.append({\n",
        "            'dataset': dataset_name,\n",
        "            'pca': apply_pca,\n",
        "            'model': 'LinearRegression',\n",
        "            'best_alpha': None,\n",
        "            'nrmse': linear_rmse\n",
        "        })\n",
        "\n",
        "        # --- Ridge Regression with GridSearchCV ---\n",
        "        ridge_pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('ridge', Ridge())\n",
        "        ])\n",
        "\n",
        "        ridge_param_grid = {'ridge__alpha': alphas}\n",
        "\n",
        "        ridge_grid_search = GridSearchCV(ridge_pipeline, ridge_param_grid, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "        ridge_grid_search.fit(X_transformed, y)\n",
        "\n",
        "        # Get best Ridge model and its NRMSE\n",
        "        best_ridge_model = ridge_grid_search.best_estimator_\n",
        "        best_ridge_nrmse = -ridge_grid_search.best_score_\n",
        "\n",
        "        # Store Ridge results\n",
        "        results.append({\n",
        "            'dataset': dataset_name,\n",
        "            'pca': apply_pca,\n",
        "            'model': 'Ridge',\n",
        "            'best_alpha': ridge_grid_search.best_params_['ridge__alpha'],\n",
        "            'nrmse': best_ridge_nrmse\n",
        "        })\n",
        "\n",
        "        # --- Lasso Regression with GridSearchCV ---\n",
        "        lasso_pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('lasso', Lasso(max_iter=10000))\n",
        "        ])\n",
        "\n",
        "        lasso_param_grid = {'lasso__alpha': alphas}\n",
        "\n",
        "        lasso_grid_search = GridSearchCV(lasso_pipeline, lasso_param_grid, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "        lasso_grid_search.fit(X_transformed, y)\n",
        "\n",
        "        # Get best Lasso model and its NRMSE\n",
        "        best_lasso_model = lasso_grid_search.best_estimator_\n",
        "        best_lasso_nrmse = -lasso_grid_search.best_score_\n",
        "\n",
        "        # Store Lasso results\n",
        "        results.append({\n",
        "            'dataset': dataset_name,\n",
        "            'pca': apply_pca,\n",
        "            'model': 'Lasso',\n",
        "            'best_alpha': lasso_grid_search.best_params_['lasso__alpha'],\n",
        "            'nrmse': best_lasso_nrmse\n",
        "        })\n",
        "\n",
        "# Convert results to DataFrame for analysis\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvjU8DZAUQm7",
        "outputId": "93e05ca6-9fe8-4d3b-a2ec-352a444e4132"
      },
      "id": "ZvjU8DZAUQm7",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/prince/pca.py:178: PerformanceWarning: Concatenating sparse arrays with multiple fill values: '[-4.571239752705203, -0.7770245319728787, -4.238602767971721, -0.6756529059473277, -0.8750733824414579, -0.7957507009624256, -1.2956724598785263, -0.8140462105290536, -0.9783617842198855, -0.17161600972671678, -4.4554107477882265, -1.804009992986325, -1.4047375809142704, -3.8201430798708222, -1.7999238948903533, -1.476296736701169, -2.481023871722075, -1.0438994335649676, -1.3994862070901652, -2.6224139250927854, -0.5289560667465164, -0.6971075269351128, -0.4540532827341345, -0.8230414693525306, -0.8917429447167244, -4.365258234292078, -1.3348592866173175, -0.7179212762581351, -3.016734149955354, -3.178372979138941, -1.1827817223561268, -4.483416933239678, -0.8407433110459417, -1.0921575981414413, -4.307527657548811, -0.34323201945343357, -0.4024752183301017, -0.618770322760204, -0.27134873684301786, -0.2972476482389081, -4.612928526331304, -0.12135084423793793, -1.1765400865854363, -0.6305574832844564, -0.21018582776148542, -4.433874893966052, -0.6421283104826384, -1.466287829861518, -4.344970324787924, -2.680727768696966, -3.6526402535587605, -0.5426974736860357, -0.8580800486335839, -0.9477803918803538, -1.808086856926896, -1.2611149665689128, -0.6067542211896897, -2.7538889065445327, -1.7417122735502604, -0.3210641552413192, -0.9399795975634877, -1.7459346125307436, -0.38374506377620377, -1.775209808167389, -1.4460622014322064, -2.7243196964048066, -1.703240264102594, -0.7480568434924517, -0.9321135212185028, -4.435535210404685, -0.5944952964778162, -3.9694898053866434, -2.146915595765811, -3.055536183693954, -3.0867036990983436, -0.7075909351502812, -0.46998979878174385, -4.475198013526772, -0.3640525327138138, -4.551870005607059, -2.276743649126009, -2.492866535064369, -4.527541290478343, -3.742252270330599, -1.1383718245630046, -2.3872521028872766, -4.585713371252903, -0.5148480291801504, -0.24270168847587587, -3.3033295780726855, -0.8494559096655656, -1.8838717054883873, -2.510525786768062, -1.50592437365828, -3.269724130627989, -2.5598988635844235, -0.7381483683505845, -1.2135084423793794, -0.7578357793698783, -2.9375929014746958, -3.2899285914722074, -0.9631924657239576, -0.7281050654276277, -4.3938390864719, -4.5112492574689, -0.43753669122072897, -1.9679799809651146, -0.8319394735623696, -3.9359599619302292, -2.669718573234635, -3.6907418417529225, -0.48540337695175173, -4.116996178556227, -1.7917237433830975, -4.403882160343506, -1.3729280778137343, -4.628862696496159, -0.5003423485508944, -0.924180495921168, -1.4862382411945403, -0.8666183688684853, -1.0785898962921736, -1.820262663569069, -1.0368220676663862, -1.0648493365678737, -1.2899771687477306, -1.1253614335689595, -1.1512351913286114, -0.6646659476141441, -4.442170270524169, -4.630453097744427, -4.595337124485127, -4.099072731761901, -2.0522289920027053, -1.2195608911092908, -0.42037165552297084, -4.200211997258925, -1.3567436842150893, -1.340363884348483, -4.319476439608019, -4.627271748624284, -4.635221027373208]'. Picking the first and converting the rest.\n",
            "  X = self.scaler_.transform(X.to_numpy())\n",
            "/usr/local/lib/python3.10/dist-packages/prince/pca.py:178: PerformanceWarning: Concatenating sparse arrays with multiple fill values: '[-4.571239752705203, -0.7770245319728787, -4.238602767971721, -0.6756529059473277, -0.8750733824414579, -0.7957507009624256, -1.2956724598785263, -0.8140462105290536, -0.9783617842198855, -0.17161600972671678, -4.4554107477882265, -1.804009992986325, -1.4047375809142704, -3.8201430798708222, -1.7999238948903533, -1.476296736701169, -2.481023871722075, -1.0438994335649676, -1.3994862070901652, -2.6224139250927854, -0.5289560667465164, -0.6971075269351128, -0.4540532827341345, -0.8230414693525306, -0.8917429447167244, -4.365258234292078, -1.3348592866173175, -0.7179212762581351, -3.016734149955354, -3.178372979138941, -1.1827817223561268, -4.483416933239678, -0.8407433110459417, -1.0921575981414413, -4.307527657548811, -0.34323201945343357, -0.4024752183301017, -0.618770322760204, -0.27134873684301786, -0.2972476482389081, -4.612928526331304, -0.12135084423793793, -1.1765400865854363, -0.6305574832844564, -0.21018582776148542, -4.433874893966052, -0.6421283104826384, -1.466287829861518, -4.344970324787924, -2.680727768696966, -3.6526402535587605, -0.5426974736860357, -0.8580800486335839, -0.9477803918803538, -1.808086856926896, -1.2611149665689128, -0.6067542211896897, -2.7538889065445327, -1.7417122735502604, -0.3210641552413192, -0.9399795975634877, -1.7459346125307436, -0.38374506377620377, -1.775209808167389, -1.4460622014322064, -2.7243196964048066, -1.703240264102594, -0.7480568434924517, -0.9321135212185028, -4.435535210404685, -0.5944952964778162, -3.9694898053866434, -2.146915595765811, -3.055536183693954, -3.0867036990983436, -0.7075909351502812, -0.46998979878174385, -4.475198013526772, -0.3640525327138138, -4.551870005607059, -2.276743649126009, -2.492866535064369, -4.527541290478343, -3.742252270330599, -1.1383718245630046, -2.3872521028872766, -4.585713371252903, -0.5148480291801504, -0.24270168847587587, -3.3033295780726855, -0.8494559096655656, -1.8838717054883873, -2.510525786768062, -1.50592437365828, -3.269724130627989, -2.5598988635844235, -0.7381483683505845, -1.2135084423793794, -0.7578357793698783, -2.9375929014746958, -3.2899285914722074, -0.9631924657239576, -0.7281050654276277, -4.3938390864719, -4.5112492574689, -0.43753669122072897, -1.9679799809651146, -0.8319394735623696, -3.9359599619302292, -2.669718573234635, -3.6907418417529225, -0.48540337695175173, -4.116996178556227, -1.7917237433830975, -4.403882160343506, -1.3729280778137343, -4.628862696496159, -0.5003423485508944, -0.924180495921168, -1.4862382411945403, -0.8666183688684853, -1.0785898962921736, -1.820262663569069, -1.0368220676663862, -1.0648493365678737, -1.2899771687477306, -1.1253614335689595, -1.1512351913286114, -0.6646659476141441, -4.442170270524169, -4.630453097744427, -4.595337124485127, -4.099072731761901, -2.0522289920027053, -1.2195608911092908, -0.42037165552297084, -4.200211997258925, -1.3567436842150893, -1.340363884348483, -4.319476439608019, -4.627271748624284, -4.635221027373208]'. Picking the first and converting the rest.\n",
            "  X = self.scaler_.transform(X.to_numpy())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      dataset    pca             model  best_alpha         nrmse\n",
            "0   numerical  False  LinearRegression         NaN  2.353773e-01\n",
            "1   numerical  False             Ridge        0.01  2.353774e-01\n",
            "2   numerical  False             Lasso        0.01  2.353773e-01\n",
            "3   numerical   True  LinearRegression         NaN  4.264154e-01\n",
            "4   numerical   True             Ridge      100.00  4.256501e-01\n",
            "5   numerical   True             Lasso      100.00  4.263713e-01\n",
            "6    complete  False  LinearRegression         NaN  1.447483e+10\n",
            "7    complete  False             Ridge      100.00  1.779988e-01\n",
            "8    complete  False             Lasso      100.00  2.057392e-01\n",
            "9    complete   True  LinearRegression         NaN  4.263776e-01\n",
            "10   complete   True             Ridge      100.00  4.256105e-01\n",
            "11   complete   True             Lasso      100.00  4.263335e-01\n",
            "12       famd  False  LinearRegression         NaN  2.547594e-01\n",
            "13       famd  False             Ridge       10.00  2.547271e-01\n",
            "14       famd  False             Lasso      100.00  2.547405e-01\n",
            "15       famd   True  LinearRegression         NaN  2.547594e-01\n",
            "16       famd   True             Ridge       10.00  2.547292e-01\n",
            "17       famd   True             Lasso      100.00  2.547452e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "import prince\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset (assuming the original dataset is loaded into df)\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Impute numerical columns with the mean\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
        "\n",
        "# Impute categorical columns with the most frequent value\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
        "\n",
        "# Apply FAMD (Factor Analysis of Mixed Data) after imputation\n",
        "famd = prince.FAMD(n_components=10, random_state=42)\n",
        "famd_df = famd.fit_transform(df.drop(columns=['SalePrice']))\n",
        "\n",
        "# Define the target variable\n",
        "y = df['SalePrice']\n",
        "\n",
        "# Define datasets based on available features\n",
        "datasets = {\n",
        "    \"numerical\": df[['GrLivArea', 'TotalBsmtSF', 'YearBuilt', 'LotArea']],  # Select features\n",
        "    \"complete\": df.drop(columns=['SalePrice']),  # All features except target\n",
        "    \"famd\": famd_df  # FAMD-transformed data\n",
        "}\n",
        "\n",
        "# Define NRMSE scorer (Normalized RMSE)\n",
        "def normalized_rmse(y_true, y_pred):\n",
        "    rmse = sqrt(mean_squared_error(y_true, y_pred))  # RMSE calculation\n",
        "    return rmse / y_true.mean()  # Normalize RMSE\n",
        "\n",
        "nrmse_scorer = make_scorer(normalized_rmse, greater_is_better=False)\n",
        "\n",
        "# Define Ridge and Lasso hyperparameters\n",
        "alphas = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through datasets\n",
        "for dataset_name, X in datasets.items():\n",
        "    # Loop through PCA options (with and without PCA)\n",
        "    for apply_pca in [False, True]:\n",
        "        # Apply PCA if selected\n",
        "        if apply_pca:\n",
        "            # One-hot encode categorical columns before applying PCA\n",
        "            X_transformed = pd.get_dummies(X, drop_first=True)\n",
        "            pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
        "            X_transformed = pca.fit_transform(X_transformed)\n",
        "            # Wrap the PCA-transformed data in a DataFrame\n",
        "            X_transformed = pd.DataFrame(X_transformed)\n",
        "        else:\n",
        "            # If no PCA, one-hot encode categorical columns\n",
        "            X_transformed = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "        # Standard scaler to ensure features are on the same scale\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # --- Polynomial Regression (Linear) ---\n",
        "        # Create a pipeline for Polynomial Regression (degree=2 as an example)\n",
        "        polynomial_pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('poly', PolynomialFeatures(degree=2)),\n",
        "            ('linear', LinearRegression())\n",
        "        ])\n",
        "\n",
        "        # Evaluate Polynomial Regression with cross-validation\n",
        "        poly_rmse_scores = -cross_val_score(polynomial_pipeline, X_transformed, y, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "        poly_rmse = poly_rmse_scores.mean()\n",
        "\n",
        "        # Store Polynomial Regression results\n",
        "        results.append({\n",
        "            'dataset': dataset_name,\n",
        "            'pca': apply_pca,\n",
        "            'model': 'PolynomialRegression',\n",
        "            'best_alpha': None,\n",
        "            'nrmse': poly_rmse\n",
        "        })\n",
        "\n",
        "        # --- Ridge Regression with Polynomial Features ---\n",
        "        ridge_poly_pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('poly', PolynomialFeatures(degree=2)),  # Same degree as polynomial regression\n",
        "            ('ridge', Ridge())\n",
        "        ])\n",
        "\n",
        "        ridge_param_grid = {'ridge__alpha': alphas}\n",
        "\n",
        "        ridge_poly_grid_search = GridSearchCV(ridge_poly_pipeline, ridge_param_grid, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "        ridge_poly_grid_search.fit(X_transformed, y)\n",
        "\n",
        "        # Get best Ridge model with polynomial features and its NRMSE\n",
        "        best_ridge_poly_model = ridge_poly_grid_search.best_estimator_\n",
        "        best_ridge_poly_nrmse = -ridge_poly_grid_search.best_score_\n",
        "\n",
        "        # Store Ridge with Polynomial features results\n",
        "        results.append({\n",
        "            'dataset': dataset_name,\n",
        "            'pca': apply_pca,\n",
        "            'model': 'RidgePoly',\n",
        "            'best_alpha': ridge_poly_grid_search.best_params_['ridge__alpha'],\n",
        "            'nrmse': best_ridge_poly_nrmse\n",
        "        })\n",
        "\n",
        "        # --- Lasso Regression with Polynomial Features ---\n",
        "        lasso_poly_pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('poly', PolynomialFeatures(degree=2)),  # Same degree as polynomial regression\n",
        "            ('lasso', Lasso(max_iter=10000))\n",
        "        ])\n",
        "\n",
        "        lasso_param_grid = {'lasso__alpha': alphas}\n",
        "\n",
        "        lasso_poly_grid_search = GridSearchCV(lasso_poly_pipeline, lasso_param_grid, cv=10, scoring=nrmse_scorer, n_jobs=-1)\n",
        "        lasso_poly_grid_search.fit(X_transformed, y)\n",
        "\n",
        "        # Get best Lasso model with polynomial features and its NRMSE\n",
        "        best_lasso_poly_model = lasso_poly_grid_search.best_estimator_\n",
        "        best_lasso_poly_nrmse = -lasso_poly_grid_search.best_score_\n",
        "\n",
        "        # Store Lasso with Polynomial features results\n",
        "        results.append({\n",
        "            'dataset': dataset_name,\n",
        "            'pca': apply_pca,\n",
        "            'model': 'LassoPoly',\n",
        "            'best_alpha': lasso_poly_grid_search.best_params_['lasso__alpha'],\n",
        "            'nrmse': best_lasso_poly_nrmse\n",
        "        })\n",
        "\n",
        "# Convert results to DataFrame for analysis\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpagk4pgah28",
        "outputId": "6d1219f1-c8da-4ebe-83dc-8936a742a197"
      },
      "id": "Tpagk4pgah28",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/prince/pca.py:178: PerformanceWarning: Concatenating sparse arrays with multiple fill values: '[-4.571239752705203, -0.7770245319728787, -4.238602767971721, -0.6756529059473277, -0.8750733824414579, -0.7957507009624256, -1.2956724598785263, -0.8140462105290536, -0.9783617842198855, -0.17161600972671678, -4.4554107477882265, -1.804009992986325, -1.4047375809142704, -3.8201430798708222, -1.7999238948903533, -1.476296736701169, -2.481023871722075, -1.0438994335649676, -1.3994862070901652, -2.6224139250927854, -0.5289560667465164, -0.6971075269351128, -0.4540532827341345, -0.8230414693525306, -0.8917429447167244, -4.365258234292078, -1.3348592866173175, -0.7179212762581351, -3.016734149955354, -3.178372979138941, -1.1827817223561268, -4.483416933239678, -0.8407433110459417, -1.0921575981414413, -4.307527657548811, -0.34323201945343357, -0.4024752183301017, -0.618770322760204, -0.27134873684301786, -0.2972476482389081, -4.612928526331304, -0.12135084423793793, -1.1765400865854363, -0.6305574832844564, -0.21018582776148542, -4.433874893966052, -0.6421283104826384, -1.466287829861518, -4.344970324787924, -2.680727768696966, -3.6526402535587605, -0.5426974736860357, -0.8580800486335839, -0.9477803918803538, -1.808086856926896, -1.2611149665689128, -0.6067542211896897, -2.7538889065445327, -1.7417122735502604, -0.3210641552413192, -0.9399795975634877, -1.7459346125307436, -0.38374506377620377, -1.775209808167389, -1.4460622014322064, -2.7243196964048066, -1.703240264102594, -0.7480568434924517, -0.9321135212185028, -4.435535210404685, -0.5944952964778162, -3.9694898053866434, -2.146915595765811, -3.055536183693954, -3.0867036990983436, -0.7075909351502812, -0.46998979878174385, -4.475198013526772, -0.3640525327138138, -4.551870005607059, -2.276743649126009, -2.492866535064369, -4.527541290478343, -3.742252270330599, -1.1383718245630046, -2.3872521028872766, -4.585713371252903, -0.5148480291801504, -0.24270168847587587, -3.3033295780726855, -0.8494559096655656, -1.8838717054883873, -2.510525786768062, -1.50592437365828, -3.269724130627989, -2.5598988635844235, -0.7381483683505845, -1.2135084423793794, -0.7578357793698783, -2.9375929014746958, -3.2899285914722074, -0.9631924657239576, -0.7281050654276277, -4.3938390864719, -4.5112492574689, -0.43753669122072897, -1.9679799809651146, -0.8319394735623696, -3.9359599619302292, -2.669718573234635, -3.6907418417529225, -0.48540337695175173, -4.116996178556227, -1.7917237433830975, -4.403882160343506, -1.3729280778137343, -4.628862696496159, -0.5003423485508944, -0.924180495921168, -1.4862382411945403, -0.8666183688684853, -1.0785898962921736, -1.820262663569069, -1.0368220676663862, -1.0648493365678737, -1.2899771687477306, -1.1253614335689595, -1.1512351913286114, -0.6646659476141441, -4.442170270524169, -4.630453097744427, -4.595337124485127, -4.099072731761901, -2.0522289920027053, -1.2195608911092908, -0.42037165552297084, -4.200211997258925, -1.3567436842150893, -1.340363884348483, -4.319476439608019, -4.627271748624284, -4.635221027373208]'. Picking the first and converting the rest.\n",
            "  X = self.scaler_.transform(X.to_numpy())\n",
            "/usr/local/lib/python3.10/dist-packages/prince/pca.py:178: PerformanceWarning: Concatenating sparse arrays with multiple fill values: '[-4.571239752705203, -0.7770245319728787, -4.238602767971721, -0.6756529059473277, -0.8750733824414579, -0.7957507009624256, -1.2956724598785263, -0.8140462105290536, -0.9783617842198855, -0.17161600972671678, -4.4554107477882265, -1.804009992986325, -1.4047375809142704, -3.8201430798708222, -1.7999238948903533, -1.476296736701169, -2.481023871722075, -1.0438994335649676, -1.3994862070901652, -2.6224139250927854, -0.5289560667465164, -0.6971075269351128, -0.4540532827341345, -0.8230414693525306, -0.8917429447167244, -4.365258234292078, -1.3348592866173175, -0.7179212762581351, -3.016734149955354, -3.178372979138941, -1.1827817223561268, -4.483416933239678, -0.8407433110459417, -1.0921575981414413, -4.307527657548811, -0.34323201945343357, -0.4024752183301017, -0.618770322760204, -0.27134873684301786, -0.2972476482389081, -4.612928526331304, -0.12135084423793793, -1.1765400865854363, -0.6305574832844564, -0.21018582776148542, -4.433874893966052, -0.6421283104826384, -1.466287829861518, -4.344970324787924, -2.680727768696966, -3.6526402535587605, -0.5426974736860357, -0.8580800486335839, -0.9477803918803538, -1.808086856926896, -1.2611149665689128, -0.6067542211896897, -2.7538889065445327, -1.7417122735502604, -0.3210641552413192, -0.9399795975634877, -1.7459346125307436, -0.38374506377620377, -1.775209808167389, -1.4460622014322064, -2.7243196964048066, -1.703240264102594, -0.7480568434924517, -0.9321135212185028, -4.435535210404685, -0.5944952964778162, -3.9694898053866434, -2.146915595765811, -3.055536183693954, -3.0867036990983436, -0.7075909351502812, -0.46998979878174385, -4.475198013526772, -0.3640525327138138, -4.551870005607059, -2.276743649126009, -2.492866535064369, -4.527541290478343, -3.742252270330599, -1.1383718245630046, -2.3872521028872766, -4.585713371252903, -0.5148480291801504, -0.24270168847587587, -3.3033295780726855, -0.8494559096655656, -1.8838717054883873, -2.510525786768062, -1.50592437365828, -3.269724130627989, -2.5598988635844235, -0.7381483683505845, -1.2135084423793794, -0.7578357793698783, -2.9375929014746958, -3.2899285914722074, -0.9631924657239576, -0.7281050654276277, -4.3938390864719, -4.5112492574689, -0.43753669122072897, -1.9679799809651146, -0.8319394735623696, -3.9359599619302292, -2.669718573234635, -3.6907418417529225, -0.48540337695175173, -4.116996178556227, -1.7917237433830975, -4.403882160343506, -1.3729280778137343, -4.628862696496159, -0.5003423485508944, -0.924180495921168, -1.4862382411945403, -0.8666183688684853, -1.0785898962921736, -1.820262663569069, -1.0368220676663862, -1.0648493365678737, -1.2899771687477306, -1.1253614335689595, -1.1512351913286114, -0.6646659476141441, -4.442170270524169, -4.630453097744427, -4.595337124485127, -4.099072731761901, -2.0522289920027053, -1.2195608911092908, -0.42037165552297084, -4.200211997258925, -1.3567436842150893, -1.340363884348483, -4.319476439608019, -4.627271748624284, -4.635221027373208]'. Picking the first and converting the rest.\n",
            "  X = self.scaler_.transform(X.to_numpy())\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}